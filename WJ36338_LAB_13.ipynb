{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53a48a2c-2b66-44d7-90ba-6c87348d9964",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from accelerate) (5.4.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install gradio\n",
    "#!pip install pyttsx3\n",
    "#!pip install transformers\n",
    "#!pip install num2words\n",
    "#!pip install faster_whisper\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a20d47-56b2-46a3-81ee-dfb24a38b94c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571c3f6a3db54f4aa2e0329c53fb8dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13fac1cb2234b779cacc9416edc5f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26356398a7024e859f7a8e00f588db73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5a5589cfce41f3b81b94a7e362317c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca54a3f4f74347bf8b5fa37cf04be8e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ac0a3203fd4d3ca0130d315bf44296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/tmp/ipykernel_427/2104872087.py:162: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chat_history = gr.Chatbot(label=\"Chat History\")  # Chat history window\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7860\n",
      "* Running on public URL: https://9be0cc00ecfdbfca98.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9be0cc00ecfdbfca98.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import pyttsx3\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import gc\n",
    "import random\n",
    "import re\n",
    "from num2words import num2words\n",
    "from faster_whisper import WhisperModel\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# apt-get install espeak\n",
    "# apt-get install ffmpeg\n",
    "HUGGINGFACE_TOKEN = \"Your Token\"\n",
    "\n",
    "\n",
    "def convert_numbers_to_words(text):\n",
    "    def replace_number(match):\n",
    "        num = int(match.group())\n",
    "        return num2words(num, to='currency')\n",
    "    return re.sub(r'\\b\\d+\\b', replace_number, text)\n",
    "\n",
    "\n",
    "def split_text_with_pauses(text):\n",
    "    text = ''.join(i for i in text if not i.isdigit())\n",
    "    chunks = re.split(r'[^\\w\\s]', text)\n",
    "    \n",
    "    chunks = [chunk.strip() for chunk in chunks if chunk.strip()]\n",
    "    \n",
    "    result = []\n",
    "    for chunk in chunks:\n",
    "        result.append(chunk)\n",
    "        result.append(\"pause\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def chunk_into_segments(str_lst, words_per_segment=5):\n",
    "    adjusted_str_lst = []\n",
    "    for text in str_lst:\n",
    "        if len(text.split(' ')) <= words_per_segment:\n",
    "            adjusted_str_lst.append(text)\n",
    "        else:\n",
    "            tmp_triplet = \"\"\n",
    "            triplet_counter = 0\n",
    "            word_lst = text.split(' ')\n",
    "            totals_words = len(word_lst)\n",
    "            for word_idx_start in range(0, totals_words, words_per_segment):\n",
    "                word_idx_end = word_idx_start+words_per_segment\n",
    "                if word_idx_end < totals_words:\n",
    "                    segment = \" \".join(word_lst[word_idx_start:word_idx_end])\n",
    "                else:\n",
    "                    segment = \" \".join(word_lst[word_idx_start:])\n",
    "                adjusted_str_lst.append(segment)\n",
    "    return adjusted_str_lst\n",
    "\n",
    "\n",
    "def setup_engine(language=\"english_wmids\"):\n",
    "    # language = \"default\"  # english_wmids, english_rp\"  # \"english\"\n",
    "    engine = pyttsx3.init()  # \"sapi5\")\n",
    "    voices = engine.getProperty(\"voices\")\n",
    "    available_voices = [voice_name.id for voice_name in engine.getProperty(\"voices\")]\n",
    "    selected_voice = available_voices[available_voices.index(language)]\n",
    "    engine.setProperty('voice', selected_voice)\n",
    "    # engine.setProperty('voice', selected_voice)\n",
    "    engine.setProperty('rate', 120)\n",
    "    engine.setProperty('volume', 0.8)\n",
    "    engine.setProperty('pitch', 130)\n",
    "    return engine\n",
    "\n",
    "\n",
    "def text_to_speech(history):  # english_wmids\"):\n",
    "    if history == []:\n",
    "        return \"\", tuple([22050, np.array([0])])\n",
    "    text_input = history[-1][1]\n",
    "    print(\"######################################################################\")\n",
    "    print(f\">>> Voicing '{text_input}'...\")\n",
    "    print(\"######################################################################\")\n",
    "    language=\"english\"\n",
    "    if os.path.exists('final_audio.wav'):\n",
    "        os.remove('final_audio.wav')\n",
    "    get_text_to_speech_model = setup_engine(language)\n",
    "    text_with_numbers_to_str = convert_numbers_to_words(text_input)\n",
    "    text_with_pauses = split_text_with_pauses(text_with_numbers_to_str)\n",
    "    text_with_pauses_adjusted = chunk_into_segments(text_with_pauses)\n",
    "    print(f\">>> Post processed to: {text_with_pauses_adjusted}\")\n",
    "    final_audio = []\n",
    "    for text_segment in text_with_pauses_adjusted:\n",
    "        print(text_segment)\n",
    "        if text_segment==\"pause\":\n",
    "            get_text_to_speech_model.save_to_file('.', 'tmp.wav')\n",
    "        else:\n",
    "            get_text_to_speech_model.save_to_file(text_segment, 'tmp.wav')\n",
    "        get_text_to_speech_model.runAndWait() # Do not forget to add this line\n",
    "        sr, data = wavfile.read('tmp.wav')\n",
    "        final_audio.append(data)\n",
    "        try:\n",
    "            os.remove(\"tmp.wav\")\n",
    "        except:\n",
    "            pass\n",
    "    final_audio = np.concatenate(final_audio).astype(np.int16)\n",
    "    # Save it back if needed\n",
    "    # wav.write(\"final_audio.wav\", sr, final_audio.astype(np.int16))\n",
    "    print(final_audio.shape, final_audio.shape)\n",
    "    return text_input, tuple([22050, final_audio])  # numpy_to_mp3(final_audio, 100)  # final_audio\n",
    "\n",
    "    \n",
    "def generate_response(user_input, audio_input, history):\n",
    "    if audio_input:\n",
    "        segments, _ = speech_to_text.transcribe(audio_input)\n",
    "        text_input = ' '.join([segment.text for segment in segments])\n",
    "    else:\n",
    "        text_input = user_input\n",
    "    if text_input == \"\":\n",
    "        response = random.choice([[\"What? I did not get that!\"], [\"Come again?\"], [\"Huh?\"], [\"What?\"]])\n",
    "        history.append((text_input, response))\n",
    "        return history, response, None, \"\", None\n",
    "    print(\"######################################################################\")\n",
    "    print(f\">>> Generating response to: {text_input}\")\n",
    "    print(\"######################################################################\")\n",
    "    messages = [\n",
    "        # {\"role\": \"system\", \"content\": \"Talk with user naturally\"},\n",
    "        {\"role\": \"user\", \"content\": text_input},\n",
    "        {\"role\": \"system\", \"content\": \"Make sure to talk with short, funny, sarcastic, and cynical tone\"}\n",
    "        # {\"role\": \"system\", \"content\": \"I always reply to user with short, funny, sarcastic, and cynical tone\"}\n",
    "    ]\n",
    "    prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    outputs = pipe(prompt, max_new_tokens=512, do_sample=True, temperature=0.7, top_k=50, top_p=0.95, repetition_penalty=1.2)\n",
    "    generated_text = outputs[0][\"generated_text\"]\n",
    "    response = generated_text[len(prompt):].strip()  # Remove the prompt part\n",
    "    response = ' '.join(generated_text.split('<|assistant|>')[1:])\n",
    "    if history is None:\n",
    "        history = []\n",
    "    history.append((text_input, response))\n",
    "    return history, response, None, \"\", None\n",
    "\n",
    "\n",
    "speech_to_text = WhisperModel(\"small\", device=\"cpu\", compute_type=\"int8\")\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "                torch_dtype=torch.float16, device_map=\"auto\",\n",
    "                token=HUGGINGFACE_TOKEN)\n",
    "    \n",
    "def startup_llm_bot():\n",
    "    \n",
    "    def terminate():\n",
    "        block.close()  # Close the Gradio application window\n",
    "        exit()\n",
    "\n",
    "    with gr.Blocks() as block:\n",
    "        gr.HTML(\n",
    "            f\"\"\"\n",
    "            <h1 style='text-align: center;'> Rusty - The Smart Bot 🤖 </h1>\n",
    "            <h3 style='text-align: center;'> Ask a question and receive the answer you will regret getting...</h3>\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        chat_history = gr.Chatbot(label=\"Chat History\")  # Chat history window\n",
    "\n",
    "        with gr.Group():\n",
    "            with gr.Row():\n",
    "                audio_out = gr.Audio(label=\"Spoken Answer\", streaming=True, autoplay=True)\n",
    "                answer = gr.Textbox(label=\"Answer\")\n",
    "                state = gr.State()\n",
    "            with gr.Row():\n",
    "                # User input textbox for typing a question\n",
    "                user_input = gr.Textbox(label=\"Message (press Enter to send):\", placeholder=\"Type your question here...\", elem_id=\"user_input\")\n",
    "                # User input for audio question\n",
    "                audio_in = gr.Audio(label=\"Speak (press again when done):\", sources=\"microphone\", type=\"filepath\", elem_id=\"audio_in\")\n",
    "                # Button to send the input when pressed\n",
    "            with gr.Row():\n",
    "                gr.Markdown(\"\")\n",
    "            with gr.Accordion(\"💀 Terminate Bot 💀\", open=False):\n",
    "                # submit_button = gr.Button(\"Ask\", elem_id=\"submit_button\")\n",
    "                terminate_button = gr.Button(\"💀\", elem_id=\"terminate_button\")  # Terminate button\n",
    "\n",
    "\n",
    "        # Set up Textbox to submit on Enter press\n",
    "        user_input.submit(generate_response, inputs=[user_input, audio_in, state], outputs=[state, answer, audio_out, user_input, audio_in])\\\n",
    "            .then(fn=text_to_speech, inputs=state, outputs=[answer, audio_out])\\\n",
    "            .then(lambda hist: hist, inputs=state, outputs=chat_history)\n",
    "        # Set up Audio input to submit when recording ends or Enter key is pressed\n",
    "        audio_in.stop_recording(generate_response, inputs=[user_input, audio_in, state], outputs=[state, answer, audio_out, user_input, audio_in])\\\n",
    "            .then(fn=text_to_speech, inputs=state, outputs=[answer, audio_out])\\\n",
    "            .then(lambda hist: hist, inputs=state, outputs=chat_history)\n",
    "        # Set up submit button to trigger the function on button press\n",
    "        # audio_in.stop_recording\n",
    "        # submit_button.click(generate_response, inputs=[user_input, audio_in, state], outputs=[state, answer, audio_out, user_input, audio_in])\\\n",
    "        #     .then(fn=text_to_speech, inputs=state, outputs=[answer, audio_out])\\\n",
    "        #     .then(lambda hist: hist, inputs=state, outputs=chat_history)\\\n",
    "        #     .then()\n",
    "\n",
    "        # audio_in.stop_recording(generate_response, inputs=[user_input, audio_in, state], outputs=[state, answer, audio_out, user_input, audio_in])\\\n",
    "        #     .then(fn=text_to_speech, inputs=state, outputs=[answer, audio_out])\\\n",
    "        #     .then(lambda hist: hist, inputs=state, outputs=chat_history)\\\n",
    "        #     .then()\n",
    "        # Set up Terminate button to close the application\n",
    "        terminate_button.click(terminate)  # Call the terminate function to stop Gradio app\n",
    "\n",
    "\n",
    "    block.css = \"\"\"\n",
    "        #user_input, #audio_in {\n",
    "            height: 200px;  /* Set height for user input, audio input, and button (button excluded) */\n",
    "        }\n",
    "        .gradio-container {\n",
    "            display: flex;\n",
    "            flex-direction: column;\n",
    "            align-items: center;\n",
    "        }\n",
    "        .gradio-row {\n",
    "            width: 100%;\n",
    "            justify-content: center;\n",
    "            align-items: center;\n",
    "            margin-bottom: 15px;\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    block.launch(server_name=\"0.0.0.0\", share=True)\n",
    "\n",
    "    \n",
    "startup_llm_bot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6033c9ea-58e9-474f-bd20-b3c94ec72e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
